# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g2z0E9Dh3orzuCz5chk8ajc5iDnYZnnW
"""

#!/usr/bin/env python3
# iris_classification.py

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

def load_data(filepath: str) -> pd.DataFrame:
    """
    Load the Iris CSV file and return a DataFrame indexed by Id.
    """
    df = pd.read_csv(filepath, index_col="Id")
    return df

def explore_data(df: pd.DataFrame):
    """
    Print basic info, summary statistics, and plot distributions and correlations.
    """
    print("Shape:", df.shape)
    print("\nSpecies counts:\n", df["Species"].value_counts())
    print("\nMissing values:\n", df.isna().sum())
    print("\nDuplicate rows:", df.duplicated().sum())

    # Summary statistics
    print("\nSummary statistics:\n", df.describe())

    # Histograms
    df.drop(columns="Species").hist(figsize=(8,6), bins=20)
    plt.tight_layout()
    plt.show()

    # Correlation heatmap
    corr = df.drop(columns="Species").corr()
    plt.figure(figsize=(6,4))
    sns.heatmap(corr, annot=True, cmap="coolwarm", vmin=-1, vmax=1)
    plt.title("Feature Correlation Matrix")
    plt.show()

    # Pairplot
    sns.pairplot(df, hue="Species", markers=["o","s","D"], corner=True)
    plt.show()

def preprocess(df: pd.DataFrame):
    """
    Encode species labels and split into training and test sets.
    """
    le = LabelEncoder()
    y = le.fit_transform(df["Species"])
    X = df.drop(columns="Species")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    return X_train, X_test, y_train, y_test, le

def train_and_evaluate(X_train, X_test, y_train, y_test):
    """
    Train a logistic regression model, evaluate accuracy,
    confusion matrix, and classification report.
    """
    # Base model
    model = LogisticRegression(max_iter=200, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=[
        "setosa", "versicolor", "virginica"
    ])

    print(f"Accuracy: {acc:.2f}\n")
    print("Confusion Matrix:")
    print(cm, "\n")
    print("Classification Report:")
    print(report)

    return model

def hyperparameter_tuning(X_train, y_train):
    """
    Example GridSearchCV for C parameter in LogisticRegression.
    """
    param_grid = {"C": [0.01, 0.1, 1, 10, 100]}
    grid = GridSearchCV(
        LogisticRegression(max_iter=200, random_state=42),
        param_grid, cv=5, scoring="accuracy"
    )
    grid.fit(X_train, y_train)
    print("Best params:", grid.best_params_)
    print(f"Best CV score: {grid.best_score_:.3f}")
    return grid.best_estimator_

def main():
    # 1. Load data
    df = load_data("Iris.csv")

    # 2. Explore
    explore_data(df)

    # 3. Preprocess
    X_train, X_test, y_train, y_test, label_encoder = preprocess(df)

    # 4. Train & Evaluate
    print("\n--- Base Model Performance ---")
    model = train_and_evaluate(X_train, X_test, y_train, y_test)

    # 5. Hyperparameter Tuning
    print("\n--- Hyperparameter Tuning ---")
    best_model = hyperparameter_tuning(X_train, y_train)

    # 6. Evaluate best model
    print("\n--- Best Model Performance on Test Set ---")
    y_best_pred = best_model.predict(X_test)
    print(f"Accuracy: {accuracy_score(y_test, y_best_pred):.2f}")

if __name__ == "__main__":
    main()