# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g4Tdog5bw2LPyIUap1OsJRv_iTVpb0kj
"""

#!/usr/bin/env python3
# car_price_prediction.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def load_data() -> pd.DataFrame:
    """
    Load the CSV file into a DataFrame.
    """
    # hard‐coded path to your attached CSV
    return pd.read_csv("car data.csv")

def explore_data(df: pd.DataFrame):
    """
    Quick EDA: shape, dtypes, missing, stats, and correlations.
    """
    print("Dataset shape:", df.shape)
    print("\nData types:\n", df.dtypes.value_counts())
    print("\nMissing values:\n", df.isna().sum())
    print("\nStatistical summary:\n", df.describe(include="all").T)

    sns.histplot(df["Selling_Price"], bins=30, kde=True)
    plt.title("Selling Price Distribution")
    plt.show()

    num_cols = df.select_dtypes(include=np.number).columns
    corr = df[num_cols].corr()
    plt.figure(figsize=(6,5))
    sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Numeric Feature Correlations")
    plt.show()

def preprocess_and_engineer(df: pd.DataFrame) -> pd.DataFrame:
    """
    Create new features and drop/transform raw ones.
    """
    current_year = pd.Timestamp.now().year
    df["Age"] = current_year - df["Year"]
    df["Brand"] = df["Car_Name"].str.split().str[0].str.lower()
    return df.drop(columns=["Car_Name", "Year"])

def build_pipeline(numeric_features, categorical_features):
    """
    Build a preprocessing + modeling pipeline.
    """
    numeric_transformer = Pipeline([("scaler", StandardScaler())])
    categorical_transformer = Pipeline([("onehot", OneHotEncoder(handle_unknown="ignore"))])

    preprocessor = ColumnTransformer([
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features),
    ])

    model = RandomForestRegressor(n_estimators=100, random_state=42)

    return Pipeline([
        ("preprocessor", preprocessor),
        ("regressor", model),
    ])

def evaluate(y_true, y_pred):
    """
    Compute and print regression metrics.
    """
    mse = mean_squared_error(y_true, y_pred)
    print(f"RMSE: {np.sqrt(mse):.3f}")
    print(f"MAE:  {mean_absolute_error(y_true, y_pred):.3f}")
    print(f"R²:   {r2_score(y_true, y_pred):.3f}")

def main():
    # 1. Load & explore
    df = load_data()
    explore_data(df)

    # 2. Preprocess & engineer features
    df_model = preprocess_and_engineer(df)
    X = df_model.drop(columns=["Selling_Price"])
    y = df_model["Selling_Price"]

    # 3. Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # 4. Build pipeline
    numeric_features = ["Present_Price", "Driven_kms", "Owner", "Age"]
    categorical_features = ["Fuel_Type", "Selling_type", "Transmission", "Brand"]
    pipeline = build_pipeline(numeric_features, categorical_features)

    # 5. Train
    pipeline.fit(X_train, y_train)

    # 6. Evaluate base model
    print("\n--- Base Model Performance ---")
    y_pred = pipeline.predict(X_test)
    evaluate(y_test, y_pred)

    # 7. Hyperparameter search (optional)
    param_dist = {
        "regressor__n_estimators": [100, 200, 300],
        "regressor__max_depth": [None, 5, 10, 20],
        "regressor__min_samples_split": [2, 5, 10],
    }
    search = RandomizedSearchCV(
        pipeline, param_distributions=param_dist,
        n_iter=10, cv=3, scoring="neg_mean_squared_error",
        random_state=42, n_jobs=-1
    )
    print("\n--- Hyperparameter Search ---")
    search.fit(X_train, y_train)
    print("Best params:", search.best_params_)

    # 8. Evaluate tuned model
    print("\n--- Tuned Model Performance ---")
    y_best = search.best_estimator_.predict(X_test)
    evaluate(y_test, y_best)

if __name__ == "__main__":
    main()